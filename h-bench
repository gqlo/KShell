#!/bin/bash

# helper script to launch kubevirt guest clusters

# set scrict mode
# set -Eeuo pipefail
set -o pipefail
# some global constants
cluster_name=$(echo $RANDOM | md5sum | head -c 10)      # random string as default cluster name
prog="${0##*/}"                                         # program name
usage="Usage: $prog [ <cluster_name> [ <test_id> ] ]"   # usage string
conf_file="$HOME/hypershift/config/.$prog.conf"         # config file name
start_time=$(date +%s)                                  # script start time
time="$(date -d "@$start_time" '+%F_%T')"               # time string
div="$(printf '=%.s' {1..40})"                          # divider line string
HCP_PARAM=""                                            # parameter string for hcp or hypershift command
KUBE_BURNER_PARAM=""                                    # parameter string for kubeburner command
PARALLEL=false                                          # determine if it's a parallel cluster creation
DEBUG=false                                             # determine if it's running in debug mode
OC=$(command -v oc)                                     # check if oc cli exists
HS=$(command -v hypershift)                             # check if hypershift cli exits
HCP=$(command -v hcp)                                   # check if hcp cli exits, for ocp >= 4.14
BC=$(command -v bc)                                     # check if bc utility is installed
OCP_VER=""                                              # ocp version
H_CMD=""                                                # hypershift or hcp command
URLENCODE=$(command -v urlencode)                       # check if urlencode exits
declare -a timing_phase=()                              # array to store timings of each phase
declare -A PROM_METRIC=()                               # store metirc name and query
declare -A JOBS=()                                      # store job names start and end time stamps
declare -i CLUSTER_NUM=1                                # number of hosted cluster to be created

#-- functions ------------------------------------------------------------------
help_msg() {
cat <<EOF
h-bench is a tool allow you to launch guest clusters within KubeVirt VMs at scale.

Usage: [Options] [name]
    Help:
        -h              Print basic help information

    Options:
        -f  jobfile     Job file describe configurations of the guest cluster. Some examples
                        are included in the examples/ directory.
        -c  name        Create guest cluster kubeconfig file at the config directory.
        -d  name        Destory the guest cluster by name. Guest kubeconfig will be deleted if exits.
        -p  profile     Extract promethus raw metrics based on provided metric profile and save it as
                        Json format. Examples are included in metric_profile/ dirctory.
        -t  file        Extract the namespace, job name (kube-burner workload or cluster creation), start
                        and end timestamp from a text file.
        -l  bool        Flag style option, indicates if create tenant cluster in parellel or sequentially,
                        deafult to: $PARALLEL.
        -n  int         Number of tenant clusters to create, default to $CLUSTER_NUM.
        -v  bool        Flag sytle option, indicates if executing in debug mode. If so print out the full hypershift
                        cli command with its parameters without creating the actual objects
        -m  name        Calculate the pod count of mgmt and hcp node. Get detailed info on running and
                        completed pod count.
EOF
}

# die fn takes an optional error message to display
# if missing, the error message defaults to the usage string
die() {
    printf '%s\n' "${@:-$usage}" >&2
    exit 1
}

# use hcp cli starting from ocp 4.14
set_hypershift_cli() {
    OCP_VER=$(oc get clusterversion version -o jsonpath='{.status.desired.version}' | awk -F "." '{print $1"."$2}')
    local new_mce=$(echo "$OCP_VER > 4.13" | bc)
    local h_cli=""

    if [[ "$new_mce" -eq 1 ]]; then
        h_cli="hcp"
    else
        h_cli="hypershift"
    fi

    H_CMD=${h_cli:-"hcp"}
}

# none of the functions below use global vars
# so all input is passed as arguments
process_option() {
    local line="$1"
    HCP_PARAM+="--$(echo "$line" | sed 's/=.*//') $(echo "$line" | sed 's/[^=]*=//') "
}

process_job_file() {
    local jobfile="$1"
    if [[ ! -f $jobfile || ! -r $jobfile ]]; then
        die "Job file does not exists or cannot be read"
    fi
    while IFS= read -r line; do
        line=$(echo "$line" | sed 's/ //g')
        if [[ $line =~ ^name= ]]; then
            cluster_name=${line##*=}
        fi
        [[ -z "$line" ]] && continue
        process_option "$line"
    done < "$jobfile"
    create_multi_clusters
}

create_cluster() {
    local cluster_param="$1"
    local cluster="$2"
    local start_time=$(date +%s)
    {
        printf '%s\n' "$div $cluster $div"
        SECONDS=0
        if [[ $DEBUG == true ]]; then
            echo "$H_CMD create cluster kubevirt $cluster_param"
            return
        else
            $H_CMD create cluster kubevirt $(echo "$cluster_param"| sed 's/"//g')
        fi
        create_secs=$SECONDS
        echo "create_secs=$create_secs"
    } &> >(tee -a "$control_log")
    log_creation_phase $cluster
    timing_phase=(${timing_phase[@]:0:1} $create_secs ${timing_phase[@]:1})
    echo "timing phase, ${timing_phase[@]}"
    write_provision_time_to_csv
    echo "Cluster=$cluster namespace=clusters-$cluster Start time: "$start_time" $(date -d "@$start_time" +"%Y-%m-%d %T") End time: $(date +%s) $(date +'%Y-%m-%d %T')" | tee -a "$time_stmp"
    echo "clusters-$cluster_name cluster-creation $start_time $(date +%s)" | tee -a "$burner_timestamp"
}

# regx matches zero or more spaces followed by "--name"
# one or more spaces and one more more characters except space
# append the first capture group with "-$i"
# use double quotes to allow variable expansion.
create_multi_clusters() {
    local n=1
    local i=1

    if [[ ! $HCP_PARAM =~ "--name" ]]; then
        HCP_PARAM+="--name $cluster_name"
    fi

    echo "CLUSTER_NUM $CLUSTER_NUM"
    if [[ $PARALLEL == true ]]; then
       for ((n=1; n<CLUSTER_NUM; n++)); do
        {
            local cluster_param=$(echo $HCP_PARAM | sed  -E "s/( *)--name[[:space:]]+([^ ]+)/\1&-$n/")
            local cluster_name=$(echo $cluster_param | sed -E "s/.*--name ([^ ]+).*/\1/")
            echo "Parallel: $cluster_param"
            create_cluster "$cluster_param" "$cluster_name"
        } &
       sleep 5
       done
       wait
    else
       for ((i=1; i<CLUSTER_NUM; i++)); do
            local cluster_param=$(echo $HCP_PARAM | sed  -E "s/( *)--name[[:space:]]+([^ ]+)/\1&-$i/")
            local cluster_name=$(echo $cluster_param | sed -E "s/.*--name ([^ ]+).*/\1/")
            echo "seq creation: $cluster_param $cluster_name"
            create_cluster "$cluster_param" "$cluster_name"
       done
    fi

    if [[ $CLUSTER_NUM == 1 ]]; then
        local cluster_param=$(echo $HCP_PARAM | sed  -E "s/( *)--name[[:space:]]+([^ ]+)/\1&/")
        local cluster_name=$(echo $cluster_param | sed -E "s/.*--name ([^ ]+).*/\1/")
        create_cluster "$cluster_param" "$cluster_name"
    fi
}

get_domain() {
    oc get ingresscontroller -n openshift-ingress-operator \
        default -o jsonpath='{.status.domain}'
}

destory_cluster() {
    local name="$1"
    if [[ -z "$HS" ]] && [[ -z "$HCP" ]]; then
        die "$H_CMD cli is not installed"
    fi
    if [[ "$1" == "--all" ]]; then
        for cluster in $(oc get hc -A | awk  'NR>1 {print $2}'); do
        {
            if [[ $DEBUG == true ]]; then
                echo "$H_CMD destroy cluster kubevirt --name $cluster"
                return
            else
                $H_CMD destroy cluster kubevirt --name "$cluster"
            fi
            [[ -f "$dir_conf/$cluster" ]] && sudo rm "$dir_conf/$cluster"
        } &
        done
    else
        if [[ $DEBUG == true ]]; then
            echo "$H_CMD destroy cluster kubevirt --name $cluster"
            return
        else
            $H_CMD destroy cluster kubevirt --name "$name"
        fi
        [[ -f "$$dir_conf/$name" ]] && sudo rm "$dir_conf/$name"
    fi
}

wait_provision() {
    local timeout="$1"
    local cluster="$2"
    let timeout+=$(date +%s)
    while sleep 5; do
        oc get vms -n "clusters-$cluster" | grep -qF "$cluster" && break
        (($(date +%s)>timeout)) \
           && die "Timeout while waiting for provisioning of $cluster"
    done
}

wait_ready() {
    local timeout="$1"
    local cluster="$2"
    oc wait --for "condition=Ready" --namespace "clusters-$cluster" \
        vm --all --timeout "${timeout}s"
    # need to figure out a way to know if it timed out or not
}

wait_available() {
    local kube_conf="$1"
    local timeout="$2"
    oc wait --for "condition=Available=True" --kubeconfig "$kube_conf" \
        co --all --timeout "${timeout}s"
    # need to figure out a way to know if it timed out or not
}

create_kubeconf() {
    local name="$1"
    $H_CMD create kubeconfig --name="$name" > "$dir_conf/$name"
}

get_nodeport() {
    local kube_conf="$1"
    oc --kubeconfig "$kube_conf" get services \
    -n openshift-ingress router-nodeport-default \
    -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}'
}

wait_nodeport() {
    local cluster="$1"
    local kube_conf="$2"
    local timeout="$3"
    let timeout+=$(date +%s)
    while sleep 2; do
        local port="$(get_nodeport "$kube_conf")"
        [[ -n "$port" ]] && break
        (($(date +%s)>timeout)) \
            && die "Timeout while waiting for nodeport on $cluster"
    done
    printf '%s\n' "$port"
}

# check if all the node-exporter pods are ready
wait_monitoring_ready() {
    local cluster="$1"
    local kube_conf="$2"
    local timeout="$3"
    local exporter_num=0
    let timeout+=$(date +%s)
    node_replica=$(echo "$HCP_PARAM" | sed -n 's/.*--node-pool-replicas \([0-9]\+\).*/\1/p')
    while ((exporter_num<node_replica)); do
        exporter_num=$(oc --kubeconfig "$kube_conf" get pod -n openshift-monitoring | grep node-exporter.*Running | wc -l)
        echo "time now $(date +%s) and timeout: $timeout"
        echo "$cluster node-exporter $exporter_num/$node_replica ready"
        sleep 5
        (($(date +%s)>timeout)) && die "Timeout while waiting for hosted cluster $cluster monitoring stack to be ready"
    done
    echo "monitoring is ready"
}

write_provision_time_to_csv() {
    local i=0
    local header=("name" "create_secs" "provision_secs" "worker_secs" "config_secs" "nodeport_secs" "operator_secs" "monitoring_secs" "total_secs")
    # if csv file doesn't exist, create it with a header line
    if [[ ! -e "$timing_csv" ]]; then
        sed 's/ /","/g;s/.*/"&"/' <<<"${header[*]}" > "$timing_csv"
    fi

    # write out the field values, first one quoted, the rest not quoted
    {   for (( i=0; i<${#timing_phase[@]}; i++ )); do
            if ((i==0)); then
                printf '"%s"' "${timing_phase[$i]}"
            else
                printf ',%s'  "${timing_phase[$i]}"
            fi
        done
        echo
    } >> "$timing_csv"
}

# integrate kube-burner tool
# use subshell to run workload to avoid environment variable clashing
# $burner_timestamp is used for python post-processing
# verbose log is saved in $burner_run_log
kube_burner_run() {
    local cluster_name="$1"
    local WORKLOAD="cluster-density-v2"
    local ITERATIONS=500
    local start_time=$(date +%s)
    local target_dir="$(pwd)"/"e2e-benchmarking/workloads/kube-burner-ocp-wrapper"
    if [[ ! -d "e2e-benchmarking" ]]; then
        git clone https://github.com/cloud-bulldozer/e2e-benchmarking.git
    fi
    if [[ ! -e "$dir_conf/$cluster_name" ]]; then
        create_kubeconf "$cluster_name"
    fi
    if [[ ! -f "$dir_conf/$cluster_name" || ! -r "$dir_conf/$cluster_name" ]]; then
        die "Tenant cluster kube-config file does not exist or it can not be read"
    fi
    {
        (export KUBECONFIG="$dir_conf/$cluster_name"
        echo "Running kube-burner $WORKLOAD workload against the following nodes"
        oc get nodes | head
        ITERATIONS="$ITERATIONS" WORKLOAD="$WORKLOAD" $target_dir/run.sh)
        local end_time=$(date +%s)
        echo "Cluster=$cluster_name workload=$WORKLOAD namespace=clusters-$cluster_name Start time: $start_time $(date -d "@$start_time" +"%Y-%m-%d %T") End time: $end_time  $(date -d "@$end_time" +"%Y-%m-%d %T")"
    }   &> >(tee -a "$burner_run_log")
    echo "clusters-$cluster_name $WORKLOAD $start_time $end_time" | tee -a "$burner_timestamp"
}

# inital version of metric profile parsing, not yet robust.
parse_metric_profile() {
    local metric_profile="$1"
    if [[ ! -f $metric_profile || ! -r $metric_profile ]]; then
        die "metric profile does not exits or can not be read"
    fi

    if [[ -z $URLENCODE ]]; then
        die "urlencode cli does not exist"
    fi

    while IFS= read -r m_name; do
        read -r m_query
            local m_name=$(echo $m_name | sed 's/://')
            local m_query=$(echo $m_query | sed 's/^ *- //g')
            # encoded_query=$(urlencode $m_query)
            PROM_METRIC[$m_name]=$m_query
    done < "$metric_profile"
}

find_max() {
    local arr="$1"
    local max=0
    for num in "${arr[@]}"; do
        if (($num > $max)); then
            max=$num
        fi
    done
    echo $max
}

# read namespace, job name(kube-burner workload name, cluster creation etc.), start and end time from a text file into bash array
# need to find a way to ensure timestamp get read first
read_timestamps() {
    local timestamp="$1"
    local line=""
    while IFS= read -r line; do
        [[ -z "$line" ]] && continue
        read -a stamps <<< "$line"
        local key="${stamps[0]}":"${stamps[1]}"
        if [[ "${!JOBS[@]}" =~ "$key" ]]; then
            die "Seems like you have duplicated workdload runs"
        fi
        JOBS[$key]="${stamps[2]}-${stamps[3]}"
        echo "$key job time start and end time gap: $(( ${stamps[3]} - ${stamps[2]} ))"
    done < "$timestamp"
}

# Extract promethus raw metrics with given profile and timestamps.
# Use scrape interval as the steps to get all data points.
prom_extract() {
    local metric_profile="$1"
    parse_metric_profile "$metric_profile"
    for job in "${!JOBS[@]}"; do
        start="${JOBS[$job]%%-*}"
        end="${JOBS[$job]##*-}"
        namespace="${job%%:*}"
        job_name="${job##*:}"
        for metric_name in "${!PROM_METRIC[@]}"; do
            QUERY_EXPRESSION=${PROM_METRIC[$metric_name]}
            if grep -q "filter" <<< "$QUERY_EXPRESSION"; then
                QUERY_EXPRESSION=${QUERY_EXPRESSION/\$filter/"namespace=\"$namespace\""}
            fi
            QUERY_EXPRESSION=$(urlencode $QUERY_EXPRESSION)
            oc exec -n openshift-monitoring -c prometheus prometheus-k8s-0 -- \
            curl -s "http://localhost:9090/api/v1/query_range?query=${QUERY_EXPRESSION}&start=${start}&end=${end}&step=5s" \
            | jq > "$dir_out/$job_name-$namespace-$metric_name".json
            echo finished extracting metrics: "$dir_out/$job_name-$namespace-$metric_name".json
        done
    done
}

count_rows() {
    local expr="$1"
    awk  "$expr"' {count++} END {print count}'
}

get_pod_count() {
    local cluster_name="$1"
    hcp_pod_count=$(oc get pod -n clusters-$cluster_name -o wide | count_rows '!/virt-lau.*/')
    running_hcp_pod_count=$(oc get pod -n clusters-$cluster_name -o wide | count_rows '/Running/ && !/virt-lau.*/')
    other_pod_count=$((hcp_pod_count-running_hcp_pod_count))
    dameon_operator_pod=$(oc get pod -A -o wide | grep 'worker001\|worker002\|worker003' | count_rows '!/clusters-kv.*/')
    running_mgmt_pod_count=$(oc get pod -o wide -A | grep -E ' +master-[0-9]+ +'| count_rows '/Running/')
    other_mgmt_pod_count=$(oc get pod -o wide -A | grep -E ' +master-[0-9]+ +'| count_rows '!/Running/')
    echo -e \
    "
    hcp pod per cluster count=$hcp_pod_count\n\
    running hcp pod per cluster count=$running_hcp_pod_count\n\
    Non-running hcp per cluster pod count=$other_pod_count\n\
    daemonset or operator pods across all hcp nodes=$dameon_operator_pod
    mgmt node running pod=$running_mgmt_pod_count\n\
    other mgmt pod=$other_mgmt_pod_count\n\
    "
}

create_ingress_service() {
    local cluster="$1"
    local namespace="$2"
    local nodeport="$3"
    oc apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  labels:
    app: $cluster
  name: apps-ingress
  namespace: $namespace
spec:
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: https-443
    port: 443
    protocol: TCP
    targetPort: $nodeport
  selector:
    kubevirt.io: virt-launcher
  sessionAffinity: None
  type: ClusterIP
EOF
}

create_ingress_route() {
    local cluster="$1"
    local namespace="$2"
    local cluster_domain="$3"
    oc apply -f - <<EOF
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: ${cluster}-443
  namespace: $namespace
spec:
  host: data.apps.$cluster_domain
  wildcardPolicy: Subdomain
  tls:
    termination: passthrough
  port:
    targetPort: https-443
  to:
    kind: Service
    name: apps-ingress
    weight: 100
EOF
}

log_creation_phase() {
    local cluster="$1"
    local start_time=$(date +%s)
    {   printf '%s\n' "$div $cluster $div" "Waiting to provision $cluster"
        SECONDS=0
        wait_provision "3600" "$cluster"
        provision_secs=$SECONDS
        echo "provision_secs=$provision_secs"
        SECONDS=0
        wait_ready "3600" "$cluster" # timeout 1 hour
        worker_secs=$SECONDS
        echo "worker_secs=$worker_secs"
    }   &> >(tee -a "$provision_log")

    {   printf '%s\n' "$div $cluster $div"
        SECONDS=0
        create_kubeconf "$cluster"
        config_secs=$SECONDS
        echo "config_secs=$config_secs"
        SECONDS=0
        nodeport="$(wait_nodeport "$cluster" "$dir_conf/$cluster" "30")"  # timeout 30 secs
        nodeport_secs=$SECONDS
        echo "nodeport_secs=$nodeport_secs"
        printf '%s\n' "$cluster https nodeport: $nodeport"
    }   &> >(tee -a "$ingress_log")

    {   printf '%s\n' "$div $cluster $div"
        SECONDS=0
        wait_available "$dir_conf/$cluster" "3600"   # timeout 1 hour
        operator_secs=$SECONDS
        echo "operator_secs=$operator_secs"
    }   &> >(tee -a "$deploy_log")

    {   printf '%s\n' "$div $cluster $div"
        SECONDS=0
        wait_monitoring_ready "$cluster" "$dir_conf/$cluster" "7200"   # timeout 1 hour
        monitoring_secs=$SECONDS
        echo "monitoring_secs=$monitoring_secs"
        total_secs="$(($(date +%s)-start_time))"
        echo "total_secs=$total_secs"
    }   &> >(tee -a "$deploy_log")
    echo "log creation phase is done"
    timing_phase=("$cluster" "$provision_secs" "$worker_secs" "$config_secs" "$nodeport_secs" "$operator_secs" "$monitoring_secs" "$total_secs")
    echo "timing phase array: ${timing_phase[@]}"
}

install_hcp_cli() {
    echo "downloading hcp cli..."
    cli_url=$(oc get ConsoleCLIDownload hcp-cli-download -o json | jq -r '.spec.links[] | select(.text | test("Linux for x86_64")).href')
    curl -k --output /tmp/hcp.tar.gz ${cli_url}
    echo "extracting hcp binary to /usr/local/bin"
    tar -xvf /tmp/hcp.tar.gz -C /usr/local/bin
    HCP=$(command -v hcp)
    if [[ -z "$HCP" ]]; then
        die "failed to install hcp cli"
    else
        echo "hcp cli is installed successfully"
    fi
}
#-- configuration --------------------------------------------------------------
# create a config file if none exists
if [[ ! -e "$conf_file" ]]; then
    cat <<'END' > "$conf_file"

#edit this config file with care (normal bash syntax)
#need to find a way to check if this config file is updated

dir_out="$HOME/hypershift/output"                               # directory containing output files
dir_conf="$HOME/hypershift/config"                              # config directory
dir_log="$HOME/hypershift/log"                                  # directory containing log files
pull_secret="$dir_conf/pull-secret"                             # file containing the pull secret key

# list of log and csv files
control_log="$dir_log/control.log"                              # control plane output
provision_log="$dir_log/provision.log"                          # provisioning phase output
ingress_log="$dir_log/ingress.log"                              # ingress phase output
deploy_log="$dir_log/deployment.log"                            # deployment phase output
timing_csv="$dir_log/timing-phase.csv"                          # timings in CSV format
time_stmp="$dir_log/stamp.log"                                  # time stamps
burner_timestamp="$dir_out/burner-run.log"                      # kube-burner workload run time stamp ready to be processed
burner_run_log="$dir_log/kube-burner-run.log"                   # kube-burner workload run log

END
    # report this to the user so they know where to find it
    echo >&2 "New config file created at $conf_file"
fi

# source the config file
source "$conf_file"

#-- Top Level -----------------------------------------------------------------
if [[ -z "$HS" ]] && [[ -z "$HCP" ]]; then
    echo "hcp cli is not installed"
    install_hcp_cli
fi

if [[ -z "$BC" ]]; then
    die "bc utility is not installed, run sudo yum install bc if you are on Red Hat distros"
fi

set_hypershift_cli

while getopts "hf:ln:c:d:p:t:m:v" opt; do
    case "$opt" in
        h) help_msg                                 ;;
        f) process_job_file "$OPTARG"               ;;
        l) PARALLEL=true                            ;;
        v) DEBUG=true                               ;;
        n) CLUSTER_NUM="$OPTARG"                    ;;
        c) create_kubeconf  "$OPTARG"               ;;
        d) destory_cluster  "$OPTARG"               ;;
        p) prom_extract     "$OPTARG"               ;;
        t) read_timestamps  "$OPTARG"               ;;
        m) get_pod_count    "$OPTARG"               ;;
        *) die "invalid options"                    ;;
    esac
done

