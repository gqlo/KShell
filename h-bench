#!/bin/bash

# helper script to launch kubevirt guest clusters

# set scrict mode
set -Eeuo pipefail

# some global constants
cluster=$(echo $RANDOM | md5sum | head -c 10)           # random string as default cluster name
prog="${0##*/}"                                         # program name
usage="Usage: $prog [ <cluster_name> [ <test_id> ] ]"   # usage string
conf_file="$HOME/hypershift/config/.$prog.conf"         # config file name
start_time=$(date +%s)                                  # script start time
time="$(date -d "@$start_time" '+%F_%T')"               # time string
div="$(printf '=%.s' {1..40})"                          # divider line string
param_string=""                                         # parameter string
OC=$(command -v oc)                                     # check if oc cli exists
HS=$(command -v hypershift)                             # check if hypershift cli exits
URLENCODE=$(command -v urlencode)                       # check if urlencode exits
declare -A PROM_METRIC=()                               # store metirc name and query
declare -A JOBS=()                                      # store job names start and end time stamps
#-- functions ------------------------------------------------------------------

help_msg() {
cat <<EOF
h-bench is a tool allow you to launch guest clusters within KubeVirt VMs at scale.

Usage: [Options] [name]
    Help:
        -h              Print basic help information

    Options:
        -f  jobfile     Job file describe configurations of the guest cluster. Some examples
                        are included in the examples/ directory.
        -c  name        Create guest cluster kubeconfig file at the config directory.
        -d  name        Destory the guest cluster by name. Guest kubeconfig will be deleted if exits.
        -p  profile     Extract promethus raw metrics based on provided metric profile and save it as Json format.
                        Examples are included in metric_profile/ dirctory.
EOF
}

# die fn takes an optional error message to display
# if missing, the error message defaults to the usage string
die() {
    printf '%s\n' "${@:-$usage}" >&2
    exit 1
}

# none of the functions below use global vars
# so all input is passed as arguments

process_option() {
    local line="$1"
    param_string+="--$(echo "$line" | sed 's/=.*//') $(echo "$line" | sed 's/[^=]*=//') "
}

process_job_file() {
    local jobfile="$1"
    if [[ ! -f $jobfile || ! -r $jobfile ]]; then
        die "Job file does not exists or cannot be read"
    fi
    while IFS= read -r line; do
        line=$(echo "$line" | sed 's/ //g')
        if [[ $line =~ ^name= ]]; then
            cluster=${line##*=}
        fi
        [[ -z "$line" ]] && continue
        process_option "$line"
    done < "$jobfile"
}

get_domain() {
    oc get ingresscontroller -n openshift-ingress-operator \
        default -o jsonpath='{.status.domain}'
}

create_cluster() {
    hypershift create cluster kubevirt $param_string
}

destory_cluster() {
    local name="$1"
    if [[ ! -z "$HS" ]]; then
        hypershift destroy cluster kubevirt --name "$name"
    else
        die "HyperShift cli is not installed"
    fi

    if [[ -f "$kube_conf" ]]; then
        sudo rm $kube_conf
    fi
    exit 0
}

wait_provision() {
    local timeout="$1"
    let timeout+=$(date +%s)
    while sleep 2; do
        oc get vms -n "clusters-$cluster" | grep -qF "$cluster" && break
        (($(date +%s)>timeout)) \
            && die "Timeout while waiting for provisioning of $cluster"
    done
}

wait_ready() {
    local timeout="$1"
    oc wait --for "condition=Ready" --namespace "clusters-$cluster" \
        vm --all --timeout "${timeout}s"
    # need to figure out a way to know if it timed out or not
}

wait_available() {
    local kube_conf="$1" timeout="$2"
    oc wait --for "condition=Available=True" --kubeconfig "$kube_conf" \
        co --all --timeout "${timeout}s"
    # need to figure out a way to know if it timed out or not
}

create_kubeconf() {
    local name="$1"
    hypershift create kubeconfig --name="$name" > "$kube_conf"
}

get_nodeport() {
    local cluster="$1" kube_conf="$2"
    oc --kubeconfig "$kube_conf" get services \
    -n openshift-ingress router-nodeport-default \
    -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}'
}

wait_nodeport() {
    local cluster="$1" kube_conf="$2" timeout="$3"
    let timeout+=$(date +%s)
    while sleep 2; do
        local port="$(get_nodeport "$cluster" "$kube_conf")"
        [[ -n "$port" ]] && break
        (($(date +%s)>timeout)) \
            && die "Timeout while waiting for nodeport on $cluster"
    done
    printf '%s\n' "$port"
}

write_provision_time_to_csv() {
    # if csv file doesn't exist, create it with a header line
    if [[ ! -e "$timing_csv" ]]; then
        sed 's/ /","/g;s/.*/"&"/' <<<"${csv_columns[*]}" > "$timing_csv"
    fi

    # write out the field values, first one quoted, the rest not quoted
    {   for (( i=0; i<${#csv_columns[@]}; i++ )); do
            declare -n val="${csv_columns[$i]}"
            if ((i==0)); then
                printf '"%s"' "$val"
            else
                printf ',%s' "$val"
            fi
        done
        echo
    } >> "$timing_csv"

}

kube_burner_run() {
    target_dir="e2e-benchmarking/workloads/kube-burner"

    if [[ ! -d "e2e-benchmarking" ]]; then
        git clone https://github.com/cloud-bulldozer/e2e-benchmarking.git
    fi

    cd $target_dir


}
# inital version of metric profile parsing, not yet robust.
parse_metric_profile() {
    local metric_profile="$1"
    if [[ ! -f $metric_profile || ! -r $metric_profile ]]; then
        die "metric profile does not exits or can not be read"
    fi

    if [[ -z $URLENCODE ]]; then
        die "urlencode cli does not exist"
    fi

    while IFS= read -r m_name; do
        read -r m_query
            m_name=$(echo $m_name | sed 's/://')
            m_query=$(echo $m_query | sed 's/^ *- //g')
            # encoded_query=$(urlencode $m_query)
            PROM_METRIC[$m_name]=$m_query
    done < "$metric_profile"
}

find_max() {
    local arr="$1"
    local max=0
    for num in "${arr[@]}"; do
        if (($num > $max)); then
            max=$num
        fi
    done
    echo $max
}

# read namespace kube-burner workload name from a text file
read_timestamps() {
    while IFS= read -r line; do
        read -a stamps <<< "$line"
        local key="${stamps[0]}":"${stamps[1]}"
        if [[ "${!JOBS[@]}" =~ "$key" ]]; then
            die "Seems like you have duplicated workdload runs"
        fi
        JOBS[$key]="${stamps[2]}"
        echo "$key workload run time spent: $(( ${stamps[3]} - ${stamps[2]} ))"
    done < "$burner_timestamp"
}

# Extract promethus raw metrics with given profile and timestamps.
# Use scrape interval as the steps to get all data points.
prom_extract() {
    parse_metric_profile "$1"
    read_timestamps
    for job in "${!JOBS[@]}"; do
        start="${JOBS[$job]}"
        end=$(( ${JOBS[$job]} + 7200 ))
        namespace="${job%%:*}"
        kube_workload="${job##*:}"
        for metric_name in "${!PROM_METRIC[@]}"; do
            QUERY_EXPRESSION=${PROM_METRIC[$metric_name]}
            if grep -q "filter" <<< "$QUERY_EXPRESSION"; then
                QUERY_EXPRESSION=${QUERY_EXPRESSION/\$filter/"namespace=\"$namespace\""}
            fi
            QUERY_EXPRESSION=$(urlencode $QUERY_EXPRESSION)
            oc exec -n openshift-monitoring -c prometheus prometheus-k8s-0 -- \
            curl -s "http://localhost:9090/api/v1/query_range?query=${QUERY_EXPRESSION}&start=${start}&end=${end}&step=30s" \
            | jq > "$dir_out/$kube_workload-$namespace-$metric_name".json
            echo finished extracting metrics: "$dir_out/$kube_workload-$namespace-$metric_name".json
        done
    done
}

create_ingress_service() {
    local cluster="$1" namespace="$2" nodeport="$3"
    oc apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  labels:
    app: $cluster
  name: apps-ingress
  namespace: $namespace
spec:
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: https-443
    port: 443
    protocol: TCP
    targetPort: $nodeport
  selector:
    kubevirt.io: virt-launcher
  sessionAffinity: None
  type: ClusterIP
EOF
}

create_ingress_route() {
    local cluster="$1" namespace="$2" cluster_domain="$3"
    oc apply -f - <<EOF
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: ${cluster}-443
  namespace: $namespace
spec:
  host: data.apps.$cluster_domain
  wildcardPolicy: Subdomain
  tls:
    termination: passthrough
  port:
    targetPort: https-443
  to:
    kind: Service
    name: apps-ingress
    weight: 100
EOF
}

#-- configuration --------------------------------------------------------------
# create a config file if none exists
if [[ ! -e "$conf_file" ]]; then
    cat <<'END' > "$conf_file"

#edit this config file with care (normal bash syntax)

dir_out="$HOME/hypershift/output"                           # directory containing output files
dir_conf="$HOME/hypershift/config"                          # config directory
dir_log="$HOME/hypershift/log"                              # directory containing log files
pull_secret="$dir_conf/pull-secret"                         # file containing the pull secret key
kube_conf="$dir_conf/$cluster-kubeconfig"                   # kubeconfig file
burner_timestamp="$dir_out/burner-run.log"                  # kube-burner run timestamp log

# list of log and csv files
control_log="$dir_log/control.log"                          # control plane output
provision_log="$dir_log/provision.log"                      # provisioning phase output
ingress_log="$dir_log/ingress.log"                          # ingress phase output
deploy_log="$dir_log/deployment.log"                        # deployment phase output
timing_csv="$dir_log/timings.csv"                           # timings in CSV format
time_stmp="$dir_log/stamp.log"                              # time stamps

END
    # report this to the user so they know where to find it
    echo >&2 "New config file created at $conf_file"
fi

# source the config file
source "$conf_file"


#-- Top Level -----------------------------------------------------------------
while getopts "hf:c:d:p:" opt; do
    case "$opt" in
        h) help_msg                                 ;;
        f) process_job_file "$OPTARG"               ;;
        c) create_kubeconf  "$OPTARG"               ;;
        d) destory_cluster  "$OPTARG"               ;;
        p) prom_extract     "$OPTARG"               ;;
        *)                                          ;;
    esac
done

echo "Cluster=$cluster namespace=clusters-$cluster Start time: $(date +%s) $(date +'%Y-%m-%d %T')" | tee -a "$time_stmp"

if [[ -z "$HS" ]]; then
    die "hypershift cli is not installed"
fi

{   printf '%s\n' "$div $cluster $div"
    SECONDS=0
    create_cluster "$param_string"
    create_secs=$SECONDS
    echo "create_secs=$create_secs"
}   &> >(tee -a "$control_log")

{   printf '%s\n' "$div $cluster $div" "Waiting to provision $cluster"
    SECONDS=0
    wait_provision "3600"
    provision_secs=$SECONDS
    echo "provision_secs=$provision_secs"
    SECONDS=0
    wait_ready "3600"  # timeout 1 hour
    worker_secs=$SECONDS
    echo "worker_secs=$worker_secs"
}   &> >(tee -a "$provision_log")

{   printf '%s\n' "$div $cluster $div"
    SECONDS=0
    create_kubeconf "$cluster"
    config_secs=$SECONDS
    echo "config_secs=$config_secs"
    SECONDS=0
    nodeport="$(wait_nodeport "$cluster" "$kube_conf" "30")"  # timeout 30 secs
    nodeport_secs=$SECONDS
    echo "nodeport_secs=$nodeport_secs"
    printf '%s\n' "$cluster https nodeport: $nodeport"
}   &> >(tee -a "$ingress_log")

{   printf '%s\n' "$div $cluster $div"
    cat <<END
END
    SECONDS=0
    wait_available "$kube_conf" "3600"   # timeout 1 hour
    operator_secs=$SECONDS
    echo "operator_secs=$operator_secs"
    total_secs="$(($(date +%s)-start_time))"
    echo "total_secs=$total_secs"
}   &> >(tee -a "$deploy_log")


#-- write timing results to csv ------------------------------------------------

csv_columns=(cluster create_secs provision_secs worker_secs config_secs
            nodeport_secs operator_secs total_secs)

write_provision_time_to_csv

echo "Cluster=$cluster namespace=clusters-$cluster End time: $(date +%s) $(date +'%Y-%m-%d %T')" | tee -a "$time_stmp"
