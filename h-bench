#!/bin/bash

# helper script to launch kubevirt guest clusters

# set scrict mode
set -Eeuo pipefail

# some global constants
prog="${0##*/}"                                         # program name
usage="Usage: $prog [ <cluster_name> [ <test_id> ] ]"   # usage string
conf_file=~/".$prog.conf"                               # config file name
start_time=$(date +%s)                                  # script start time
time="$(date -d "@$start_time" '+%F_%T')"               # time string
div="$(printf '=%.s' {1..40})"                          # divider line string
param_string=""                                         # parameter string
OC=$(command -v oc)                                     # check if oc cli exists
HS=$(command -v hypershift)                             # check if hypershift cli exits
URLENCODE=$(command -v urlencode)                       # check if urlencode exits
declare -A PROM_METRIC=()                               # store metirc name and query
#-- functions ------------------------------------------------------------------

help_msg() {
cat <<EOF
h-bench is a tool allow you to launch guest clusters within KubeVirt VMs at scale.

Usage: [Options] [name]
    Help:
        -h              Print basic help information

    Options:
        -f  jobfile     Job file describe configurations of the guest cluster. Some examples
                        are included in the examples/ directory.
        -c  name        Create guest cluster kubeconfig file at the config directory.
        -d  name        Destory the guest cluster by name. Guest kubeconfig will be deleted if exits.
        -p  profile     Extract promethus raw metrics based on provided metric profile and save it as Json format.
                        Examples are included in metric_profile/ dirctory.
EOF
}

# die fn takes an optional error message to display
# if missing, the error message defaults to the usage string
die() {
    printf '%s\n' "${@:-$usage}" >&2
    exit 1
}

# none of the functions below use global vars
# so all input is passed as arguments

process_option() {
    local line="$1"
    param_string+="--$(echo "$line" | sed 's/=.*//') $(echo "$line" | sed 's/[^=]*=//') "
}

process_job_file() {
    local jobfile="$1"
    if [[ ! -f $jobfile || ! -r $jobfile ]]; then
        die "Job file does not exists or cannot be read"
    fi
    while IFS= read -r line; do
        line=$(echo "$line" | sed 's/ //g')
        [[ -z "$line" ]] && continue
        process_option "$line"
    done < "$jobfile"
}

get_domain() {
    oc get ingresscontroller -n openshift-ingress-operator \
        default -o jsonpath='{.status.domain}'
}

create_cluster() {
    local pull_secret="$1"
    hypershift create cluster kubevirt --pull-secret "$pull_secret" $param_string
}

destory_cluster() {
    local cluster="$1"
    if [[ ! -z "$HS" ]]; then
        hypershift destroy cluster kubevirt --name "$cluster"
    else
        die "HyperShift cli is not installed"
    fi

    if [[ -f "$kube_conf" ]]; then
        sudo rm $kube_conf
    fi
}

wait_provision() {
    local cluster="$1" namespace="$2" timeout="$3"
    let timeout+=$(date +%s)
    while sleep 2; do
        oc get vms -n "$namespace" | grep -qF "$cluster" && break
        (($(date +%s)>timeout)) \
            && die "Timeout while waiting for provisioning of $cluster"
    done
}

wait_ready() {
    local namespace="$1" timeout="$2"
    oc wait --for "condition=Ready" --namespace "$namespace" \
        vm --all --timeout "${timeout}s"
    # need to figure out a way to know if it timed out or not
}

wait_available() {
    local kube_conf="$1" timeout="$2"
    oc wait --for "condition=Available=True" --kubeconfig "$kube_conf" \
        co --all --timeout "${timeout}s"
    # need to figure out a way to know if it timed out or not
}

create_kubeconf() {
    local cluster="$1"
    hypershift create kubeconfig --name="$cluster" > "$cluster"_kubeconfig
}

get_nodeport() {
    local cluster="$1" kube_conf="$2"
    oc --kubeconfig "$kube_conf" get services \
    -n openshift-ingress router-nodeport-default \
    -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}'
}

wait_nodeport() {
    local cluster="$1" kube_conf="$2" timeout="$3"
    let timeout+=$(date +%s)
    while sleep 2; do
        local port="$(get_nodeport "$cluster" "$kube_conf")"
        [[ -n "$port" ]] && break
        (($(date +%s)>timeout)) \
            && die "Timeout while waiting for nodeport on $cluster"
    done
    printf '%s\n' "$port"
}

write_provision_time_to_csv() {
    # if csv file doesn't exist, create it with a header line
    if [[ ! -e "$timing_csv" ]]; then
        sed 's/ /","/g;s/.*/"&"/' <<<"${csv_columns[*]}" > "$timing_csv"
    fi

    # write out the field values, first one quoted, the rest not quoted
    {   for (( i=0; i<${#csv_columns[@]}; i++ )); do
            declare -n val="${csv_columns[$i]}"
            if ((i==0)); then
                printf '"%s"' "$val"
            else
                printf ',%s' "$val"
            fi
        done
        echo
    } >> "$timing_csv"

}

# inital version of metric profile parsing, not yet robust.
parse_metric_profile() {
    local metric_profile="$1"
    if [[ ! -f $metric_profile || ! -r $metric_profile ]]; then
        die "metric profile does not exits or can not be read"
    fi

    if [[ -z $URLENCODE ]]; then
        die "urlencode cli does not exist"
    fi

    while IFS= read -r m_name; do
        read -r m_query
            m_name=$(echo $m_name | sed 's/://')
            m_query=$(echo $m_query | sed 's/^ *- //g')
            encoded_query=$(urlencode $m_query)
            PROM_METRIC[$m_name]=$encoded_query
    done < "$metric_profile"
}

# extract promethus raw metrics with given profile and timestamps.
# Use scrape interval as the steps to get all data points.
prom_extract() {
    local start="1682333803" end="1682335521" # placeholder, testing only
    parse_metric_profile "$1"
    for metric_name in "${!PROM_METRIC[@]}"; do
        QUERY_EXPRESSION=${PROM_METRIC[$metric_name]}
        oc exec -n openshift-monitoring -c prometheus prometheus-k8s-0 -- \
        curl -s "http://localhost:9090/api/v1/query_range?query=${QUERY_EXPRESSION}&start=${start}&end=${end}&step=30s" \
        | jq > "$metric_name".json
    done
}

create_ingress_service() {
    local cluster="$1" namespace="$2" nodeport="$3"
    oc apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  labels:
    app: $cluster
  name: apps-ingress
  namespace: $namespace
spec:
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: https-443
    port: 443
    protocol: TCP
    targetPort: $nodeport
  selector:
    kubevirt.io: virt-launcher
  sessionAffinity: None
  type: ClusterIP
EOF
}

create_ingress_route() {
    local cluster="$1" namespace="$2" cluster_domain="$3"
    oc apply -f - <<EOF
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: ${cluster}-443
  namespace: $namespace
spec:
  host: data.apps.$cluster_domain
  wildcardPolicy: Subdomain
  tls:
    termination: passthrough
  port:
    targetPort: https-443
  to:
    kind: Service
    name: apps-ingress
    weight: 100
EOF
}

#-- configuration --------------------------------------------------------------

# create a config file if none exists
if [[ ! -e "$conf_file" ]]; then
    cat <<'END' > "$conf_file"

#edit this config file with care (normal bash syntax)

cluster=$(echo $RANDOM | md5sum | head -c 10)           # random string as default cluster name
dir=~/"work/output"                             	# working directory containing output files
dir_conf=~/"work/config"                                # config directory
pull_secret="$dir_conf/pull-secret"                     # file containing the pull secret key
kube_conf="$dir_conf/kubeconfig"                        # kubeconfig file

# list of log and csv files
control_log="$dir/control.log"                          # control plane output
provision_log="$dir/provision.log"                      # provisioning phase output
ingress_log="$dir/ingress.log"                          # ingress phase output
deploy_log="$dir/deployment.log"                        # deployment phase output
timing_csv="$dir/timings.csv"                           # timings in CSV format
time_stmp="$dir/stamp.log"	                        # time stamps 

END
    # report this to the user so they know where to find it
    echo >&2 "New config file created at $conf_file"
fi

# source the config file
source "$conf_file"

#-- Top Level -----------------------------------------------------------------
while getopts "hf:c:d:p:" opt; do
    case "$opt" in
        h) help_msg                                 ;;
        f) process_job_file "$OPTARG"               ;;
        c) create_kubeconf    "$OPTARG"               ;;
        d) destory_cluster  "$OPTARG"               ;;
        p) prom_extract     "$OPTARG"               ;;
        *)                                          ;;
    esac
done

exit 0

echo "Start time: $(date +%s) $(date +'%Y-%m-%d %T')" | tee -a "$time_stmp"

if [[ -z "$HS" ]]; then
    die "hypershift cli is not installed"
fi

{   printf '%s\n' "$div $cluster $div"
    SECONDS=0
    create_cluster "$pull_secret $param_string"
    create_secs=$SECONDS
    echo "create_secs=$create_secs"
}   &> >(tee -a "$control_log")

{   printf '%s\n' "$div $cluster $div" "Waiting to provision $cluster"
    SECONDS=0
    wait_provision "$cluster" "$namespace" "1800"
    provision_secs=$SECONDS
    echo "provision_secs=$provision_secs"
    SECONDS=0
    wait_ready "$namespace" "1800"  # timeout 30 mins
    worker_secs=$SECONDS
    echo "worker_secs=$worker_secs"
}   &> >(tee -a "$provision_log")

{   printf '%s\n' "$div $cluster $div"
    SECONDS=0
    create_kubeconf "$cluster" "$kube_conf"
    config_secs=$SECONDS
    echo "config_secs=$config_secs"
    SECONDS=0
    nodeport="$(wait_nodeport "$cluster" "$kube_conf" "30")"  # timeout 30 secs
    nodeport_secs=$SECONDS
    echo "nodeport_secs=$nodeport_secs"
    printf '%s\n' "$cluster https nodeport: $nodeport"
}   &> >(tee -a "$ingress_log")

{   printf '%s\n' "$div $cluster $div"
    cat <<END
END
    SECONDS=0
    wait_available "$kube_conf" "3600"   # timeout 10 mins
    operator_secs=$SECONDS
    echo "operator_secs=$operator_secs"
    total_secs="$(($(date +%s)-start_time))"
    echo "total_secs=$total_secs"
}   &> >(tee -a "$deploy_log")


#-- write timing results to csv ------------------------------------------------

csv_columns=(cluster create_secs provision_secs worker_secs config_secs
            nodeport_secs operator_secs total_secs)

echo "Finished time: $(date +%s) $(date +'%Y-%m-%d %T')" | tee -a "$time_stmp"

